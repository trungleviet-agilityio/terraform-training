#!/bin/bash
set -euo pipefail

# Script to build and test runtime packages

# Usage: 
#   cb                           - Show help
#   cb build                     - Package all packages into out/
#   cb test                      - Run build, then run tests against packages in out/
#   cb deploy                    - Run build, then deploy infrastructure with terraform
#   cb run <package> <command>   - Run command in package environment (alias for cybernetika-runner)
#   cb build --only <package>    - Build only specified package
#   cb test --only <package>     - Test only specified package (runs build first)

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Get script directory and project root
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)"
cd "$PROJECT_ROOT"

# Default values
ENV="dev"
ONLY_PACKAGE=""
ONLY_LAYER=""

# Package directories
SRC_LAMBDA_DIR="$PROJECT_ROOT/src/lambda"
SRC_RUNTIME_DIR="$PROJECT_ROOT/src/runtime"
OUT_DIR="$PROJECT_ROOT/out"
DEPLOY_DIR="$PROJECT_ROOT/deploy"

# Layer mappings
declare -A LAYER_MAP=(
  ["core"]="10_core"
  ["infra"]="20_infra"
  ["app"]="30_app"
)

# Print colored output
_print_info() {
  echo -e "${BLUE}ℹ${NC} $*"
}

_print_success() {
  echo -e "${GREEN}✓${NC} $*"
}

_print_warning() {
  echo -e "${YELLOW}⚠${NC} $*"
}

_print_error() {
  echo -e "${RED}✗${NC} $*" >&2
}

# Show help/usage
_show_help() {
  cat << EOF
cb - Unified Developer CLI Tool

Usage:
  cb                           - Show help
  cb build                     - Package all packages into out/
  cb test                      - Run build, then run tests against packages in out/
  cb deploy                    - Run build, then deploy infrastructure with terraform
  cb run <package> <command>   - Run command in package environment

Options:
  --env <dev|stage|prod>       - Environment selection (default: dev)
  --only <package|layer>       - Build/test/deploy only specified package or layer
                                  Layers: core, infra, app
  --help                       - Show this help message

Examples:
  cb build
  cb build --only lambda-api
  cb test --only lambda-worker
  cb deploy --env dev
  cb deploy --only core --env prod
  cb run lambda-api python -m pytest
EOF
}

# Parse command line arguments
parse_args() {
  local cmd=""
  local args=()

  while [[ $# -gt 0 ]]; do
    case "$1" in
      --env)
        if [[ -z "${2:-}" ]]; then
          _print_error "Error: --env requires an argument"
          exit 1
        fi
        ENV="$2"
        if [[ ! "$ENV" =~ ^(dev|stage|prod)$ ]]; then
          _print_error "Error: Environment must be one of: dev, stage, prod"
          exit 1
        fi
        shift 2
        ;;
      --only)
        if [[ -z "${2:-}" ]]; then
          _print_error "Error: --only requires an argument"
          exit 1
        fi
        # Check if it's a layer or package
        if [[ -v LAYER_MAP["$2"] ]]; then
          ONLY_LAYER="$2"
        else
          ONLY_PACKAGE="$2"
        fi
        shift 2
        ;;
      --help|-h)
        # Help is handled in main() before parse_args is called
        # But if we reach here, show help and exit
        _show_help
        exit 0
        ;;
      build|test|deploy|run)
        cmd="$1"
        shift
        args=("$@")
        break
        ;;
      *)
        if [[ -z "$cmd" ]]; then
          _print_error "Error: Unknown option or command: $1"
          _show_help
          exit 1
        else
          args+=("$1")
        fi
        shift
        ;;
    esac
  done

  # If no command provided, show help
  if [[ -z "$cmd" ]]; then
    _show_help
    exit 0
  fi

  echo "$cmd"
  printf '%s\n' "${args[@]}"
}

# Check prerequisites
check_prerequisites() {
  local missing=()

  if ! command -v terraform &> /dev/null; then
    missing+=("terraform")
  fi

  if ! command -v aws &> /dev/null; then
    missing+=("aws")
  fi

  if [[ ${#missing[@]} -gt 0 ]]; then
    _print_error "Missing required tools: ${missing[*]}"
    _print_info "Please install the missing tools and try again"
    exit 1
  fi
}

# Check if UV is available (required for Python packages)
check_uv() {
  if ! command -v uv &> /dev/null; then
    _print_error "UV is required for Python package management but not found"
    _print_info "Please install UV: https://github.com/astral-sh/uv"
    exit 1
  fi
}

# Detect available packages in src/lambda/
# Returns packages that should be built as runtime modules (have pyproject.toml)
_detect_packages() {
  local packages=()

  if [[ ! -d "$SRC_LAMBDA_DIR" ]]; then
    return 0
  fi

  # Find all directories in src/lambda/ with pyproject.toml (runtime modules)
  while IFS= read -r -d '' dir; do
    [[ -z "$dir" ]] && continue
    local pkg_name=$(basename "$dir")
    # Skip hidden directories and ensure name is not empty
    if [[ -n "$pkg_name" ]] && [[ ! "$pkg_name" =~ ^\. ]] && [[ -f "$dir/pyproject.toml" ]]; then
      packages+=("$pkg_name")
    fi
  done < <(find "$SRC_LAMBDA_DIR" -mindepth 1 -maxdepth 1 -type d -print0 2>/dev/null || true)

  # Only output non-empty package names
  for pkg in "${packages[@]}"; do
    [[ -n "$pkg" ]] && echo "$pkg"
  done
}

# Check if a directory contains Python code
_is_python_package() {
  local dir="$1"
  [[ -f "$dir/requirements.txt" ]] || [[ -f "$dir/pyproject.toml" ]] || [[ -f "$dir/Pipfile" ]] || \
  find "$dir" -maxdepth 1 -name "*.py" -type f | grep -q .
}

# Detect available runtime modules in src/runtime/
_detect_runtime_modules() {
  local modules=()

  if [[ ! -d "$SRC_RUNTIME_DIR" ]]; then
    return 0
  fi

  # Find all directories in src/runtime/ with pyproject.toml
  while IFS= read -r -d '' dir; do
    [[ -z "$dir" ]] && continue
    local mod_name=$(basename "$dir")
    # Skip hidden directories and ensure name is not empty
    if [[ -n "$mod_name" ]] && [[ ! "$mod_name" =~ ^\. ]] && [[ -f "$dir/pyproject.toml" ]]; then
      modules+=("$mod_name")
    fi
  done < <(find "$SRC_RUNTIME_DIR" -mindepth 1 -maxdepth 1 -type d -print0 2>/dev/null || true)

  # Only output non-empty module names
  for mod in "${modules[@]}"; do
    [[ -n "$mod" ]] && echo "$mod"
  done
}

# Build a runtime module (creates layer and app zips with signatures.json)
# Can build modules from either src/runtime/ or src/lambda/
_build_runtime_module() {
  local module="$1"
  local base_dir="${2:-$SRC_RUNTIME_DIR}"  # Default to runtime, can override to lambda
  local module_dir="$base_dir/$module"
  local OUTPUT_DIR="$OUT_DIR/$module"
  local LAYER_DIR="$OUTPUT_DIR/layer"
  local SOURCES_DIR="$OUTPUT_DIR/sources"
  local SIGNATURES_FILE="$OUTPUT_DIR/signatures.json"
  local PYTHON_VERSION="3.13"
  local TARGET_PLATFORM="manylinux2014_x86_64"
  local PYPROJECT_TOML="$module_dir/pyproject.toml"
  local SRC_DIR="$module_dir/src"

  if [[ ! -d "$module_dir" ]] || [[ ! -f "$PYPROJECT_TOML" ]]; then
    _print_error "Runtime module not found or missing pyproject.toml: $module_dir"
    return 1
  fi

  # For lambda packages, source files are directly in the package directory, not in src/
  if [[ "$base_dir" == "$SRC_LAMBDA_DIR" ]]; then
    # Lambda packages: source files are in the root of the package directory
    SRC_DIR="$module_dir"
  elif [[ ! -d "$SRC_DIR" ]]; then
    _print_error "Source directory not found: $SRC_DIR"
    return 1
  fi

  _print_info "Building runtime module: $module"

  check_uv

  # Create output directories
  mkdir -p "$OUTPUT_DIR"
  mkdir -p "$LAYER_DIR"
  mkdir -p "$SOURCES_DIR"

  # Set up absolute paths for ZIP files
  local APP_OUTPUT_ZIP="$(realpath "$OUTPUT_DIR")/lambda_app.zip"
  local LAYER_OUTPUT_ZIP="$(realpath "$OUTPUT_DIR")/lambda_layer.zip"

  cd "$module_dir"

  # Step 0: Pre-install editable dependencies (if any) so uv export can resolve them
  _print_info "  Step 0: Checking for editable dependencies..."

  # Extract practice-* dependencies from pyproject.toml
  local practice_deps=$(awk '
    /^dependencies = \[/ { in_deps = 1; next }
    in_deps && /^\]/ { in_deps = 0; next }
    in_deps && /practice[_-]/ {
      gsub(/[",]/, "")
      gsub(/>=.*/, "")
      gsub(/^[[:space:]]*/, "")
      gsub(/[[:space:]]*$/, "")
      if ($0 ~ /practice[_-]/) {
        print $0
      }
    }
  ' "$PYPROJECT_TOML")

  # Install editable dependencies temporarily so uv export can resolve them
  if [[ -n "$practice_deps" ]]; then
    _print_info "    Installing editable dependencies for uv export resolution..."

    # Create a temporary virtual environment with the correct Python version
    local TEMP_VENV=$(mktemp -d)
    trap "rm -rf '$TEMP_VENV'" EXIT INT TERM

    _print_info "      - Creating temporary virtual environment with Python ${PYTHON_VERSION}..."
    uv venv "$TEMP_VENV" --python "python${PYTHON_VERSION}" || {
      _print_error "    Failed to create temporary virtual environment"
      return 1
    }

    # Activate the virtual environment
    source "$TEMP_VENV/bin/activate" || {
      _print_error "    Failed to activate virtual environment"
      return 1
    }

    for dep in $practice_deps; do
      local package_name=$(echo "$dep" | sed 's/-/_/g')
      local package_path="$SRC_RUNTIME_DIR/$package_name"

      if [[ -d "$package_path" ]] && [[ -f "$package_path/pyproject.toml" ]]; then
        _print_info "      - Installing $package_name in editable mode"
        uv pip install -e "$package_path" --quiet || {
          _print_error "    Failed to install editable dependency: $package_name"
          deactivate 2>/dev/null || true
          return 1
        }
      fi
    done

    # Install the current package in editable mode so uv export can resolve it
    _print_info "      - Installing current package in editable mode for uv export"
    uv pip install -e . --quiet || {
      _print_error "    Failed to install current package in editable mode"
      deactivate 2>/dev/null || true
      return 1
    }
  fi

  # Step 1: Package layer dependencies
  _print_info "  Step 1: Packaging layer dependencies..."

  # Calculate hash of pyproject.toml
  local PACKAGE_PYPROJECT_HASH=$(shasum -a 256 "$PYPROJECT_TOML" | awk '{print $1}')
  local PYPROJECT_HASH_FILE="$OUTPUT_DIR/.pyproject_hash"

  # Check if pyproject.toml has changed
  local REBUILD_LAYER=true
  if [[ -f "$PYPROJECT_HASH_FILE" ]] && [[ -d "$LAYER_DIR" ]]; then
    local OLD_HASH=$(cat "$PYPROJECT_HASH_FILE")
    if [[ "$OLD_HASH" == "$PACKAGE_PYPROJECT_HASH" ]]; then
      _print_info "    No changes in pyproject.toml. Skipping layer rebuild."
      REBUILD_LAYER=false
    fi
  fi

  if [[ "$REBUILD_LAYER" == true ]]; then
    _print_info "    Changes detected in pyproject.toml. Rebuilding layer..."

    # Clean up previous layer directory
    rm -rf "$LAYER_DIR"
    mkdir -p "$LAYER_DIR/python/lib/python${PYTHON_VERSION}/site-packages"

    # Generate requirements file with uv (must use venv if created above)
    _print_info "    Generating requirements file with uv..."
    local REQUIREMENTS_FILE="$OUTPUT_DIR/requirements.txt"

    # If we created a venv, use uv pip freeze to get all installed packages
    # Then filter out editable dependencies (they'll be included via symlinks)
    # Otherwise use uv export
    if [[ -n "${TEMP_VENV:-}" ]] && [[ -d "$TEMP_VENV" ]] && [[ -n "${VIRTUAL_ENV:-}" ]]; then
      # Venv is active, use uv pip freeze to get all installed packages
      # Filter out editable packages (lines starting with -e or containing file://)
      uv pip freeze | grep -v -E "^-e |file://" > "$REQUIREMENTS_FILE" || {
        _print_error "    Failed to generate requirements file"
        deactivate 2>/dev/null || true
        return 1
      }
    else
      # No venv, use system uv export
      uv export --no-dev --no-hashes --format requirements-txt > "$REQUIREMENTS_FILE" || {
        _print_error "    Failed to generate requirements file"
        return 1
      }
    fi

    # Deactivate venv after generating requirements (no longer needed)
    if [[ -n "${VIRTUAL_ENV:-}" ]] && [[ "${VIRTUAL_ENV:-}" == "$TEMP_VENV"* ]]; then
      deactivate 2>/dev/null || true
    fi

    # Filter out editable dependencies (practice-*) from requirements file
    # These will be included via symlinks, not installed in the layer
    if [[ -n "$practice_deps" ]]; then
      _print_info "    Filtering out editable dependencies from requirements..."
      local TEMP_REQUIREMENTS=$(mktemp)
      # Filter out lines starting with practice- or practice_ (package names)
      # Also filter out file:// paths to practice packages
      grep -v -E "(^practice[-_]|file://.*practice[-_])" "$REQUIREMENTS_FILE" > "$TEMP_REQUIREMENTS" || true
      mv "$TEMP_REQUIREMENTS" "$REQUIREMENTS_FILE"
    fi

    # Install dependencies from requirements file
    _print_info "    Installing dependencies from requirements file..."
    local pip_command="pip${PYTHON_VERSION}"
    if ! command -v "$pip_command" &> /dev/null; then
      pip_command="pip3"
    fi

    if ! $pip_command install -r "$REQUIREMENTS_FILE" \
      --target "$LAYER_DIR/python/lib/python${PYTHON_VERSION}/site-packages" \
      --platform "$TARGET_PLATFORM" \
      --python-version "${PYTHON_VERSION}" \
      --only-binary=:all: \
      --no-deps; then
      _print_error "    Failed to install dependencies"
      return 1
    fi

    # Save the new pyproject hash
    echo "$PACKAGE_PYPROJECT_HASH" > "$PYPROJECT_HASH_FILE"
  fi

  # Step 2: Find editable packages (practice-util dependencies)
  _print_info "  Step 2: Finding editable packages..."

  local SITE_PACKAGES_DIR="$LAYER_DIR/python/lib/python${PYTHON_VERSION}/site-packages"
  local EDITABLE_MODULES=""
  local EDITABLE_PATHS=""

  # Extract practice-* dependencies from pyproject.toml
  local practice_deps=$(awk '
    /^dependencies = \[/ { in_deps = 1; next }
    in_deps && /^\]/ { in_deps = 0; next }
    in_deps && /practice[_-]/ {
      gsub(/[",]/, "")
      gsub(/>=.*/, "")
      gsub(/^[[:space:]]*/, "")
      gsub(/[[:space:]]*$/, "")
      if ($0 ~ /practice[_-]/) {
        print $0
      }
    }
  ' "$PYPROJECT_TOML")

  # For each practice dependency, find the corresponding runtime package
  for dep in $practice_deps; do
    # Convert package name format (practice-util -> practice_util)
    local package_name=$(echo "$dep" | sed 's/-/_/g')
    local package_path="$SRC_RUNTIME_DIR/$package_name"

    if [[ -d "$package_path" ]]; then
      _print_info "      - Found editable module: $package_name at $package_path"
      EDITABLE_MODULES="$EDITABLE_MODULES $package_name"
      EDITABLE_PATHS="$EDITABLE_PATHS $package_path"

      # Remove the module from the layer if it exists
      local module_underscore=$(echo "$dep" | sed 's/-/_/g')
      local module_dash=$(echo "$dep" | sed 's/_/-/g')

      for module_variant in "$module_underscore" "$module_dash"; do
        if [[ -d "$SITE_PACKAGES_DIR/$module_variant" ]]; then
          _print_info "        Removing $module_variant from layer"
          rm -rf "$SITE_PACKAGES_DIR/$module_variant"
        fi

        # Remove the dist-info directory
        for dist_info in "$SITE_PACKAGES_DIR"/${module_variant}*.dist-info; do
          if [[ -d "$dist_info" ]]; then
            rm -rf "$dist_info"
          fi
        done
      done
    fi
  done

  # Step 3: Create sources directory with symlinks
  _print_info "  Step 3: Creating sources directory with symlinks..."

  # Clean up previous sources directory
  rm -rf "$SOURCES_DIR"
  mkdir -p "$SOURCES_DIR"

  # Symlink the current package sources
  _print_info "    - Symlinking current package sources"
  if [[ "$base_dir" == "$SRC_LAMBDA_DIR" ]]; then
    # Lambda packages: symlink Python files directly
    for file in "$SRC_DIR"/*.py; do
      if [[ -e "$file" ]]; then
        ln -sf "$(realpath "$file")" "$SOURCES_DIR/$(basename "$file")"
      fi
    done
    # Also symlink __init__.py if it exists
    if [[ -f "$SRC_DIR/__init__.py" ]]; then
      ln -sf "$(realpath "$SRC_DIR/__init__.py")" "$SOURCES_DIR/__init__.py"
    fi
  else
    # Runtime modules: symlink entire src/ directory contents
    for file in "$SRC_DIR"/*; do
      if [[ -e "$file" ]]; then
        ln -sf "$(realpath "$file")" "$SOURCES_DIR/$(basename "$file")"
      fi
    done
  fi

  # Symlink all editable module sources
  if [[ -n "$EDITABLE_PATHS" ]]; then
    _print_info "    Symlinking editable module sources..."
    IFS=' ' read -r -a path_array <<< "$EDITABLE_PATHS"
    IFS=' ' read -r -a name_array <<< "$EDITABLE_MODULES"

    for i in "${!path_array[@]}"; do
      local module_path="${path_array[$i]}"
      local module_name="${name_array[$i]}"

      if [[ -n "$module_path" ]] && [[ -d "$module_path/src" ]]; then
        _print_info "      - Symlinking $module_name sources from $module_path"
        for file in "$module_path/src"/*; do
          if [[ -e "$file" ]]; then
            ln -sf "$(realpath "$file")" "$SOURCES_DIR/$(basename "$file")"
          fi
        done
      fi
    done
  fi

  # Step 4: Build zip files
  _print_info "  Step 4: Building zip files..."

  # Calculate hashes
  local LAYER_HASH=$(find -L "$LAYER_DIR" -type f -print0 2>/dev/null | sort -z | xargs -0 shasum -a 256 2>/dev/null | shasum -a 256 | awk '{print $1}')
  local SOURCES_HASH=$(find -L "$SOURCES_DIR" -type f -print0 2>/dev/null | sort -z | xargs -0 shasum -a 256 2>/dev/null | shasum -a 256 | awk '{print $1}')

  local LAYER_HASH_FILE="$OUTPUT_DIR/.layer_hash"
  local APP_HASH_FILE="$OUTPUT_DIR/.app_hash"

  # Check if layer needs to be rebuilt
  local REBUILD_LAYER_ZIP=true
  if [[ -f "$LAYER_HASH_FILE" ]] && [[ -f "$LAYER_OUTPUT_ZIP" ]]; then
    local OLD_HASH=$(cat "$LAYER_HASH_FILE")
    if [[ "$OLD_HASH" == "$LAYER_HASH" ]]; then
      _print_info "    No changes detected in layer. Skipping layer zip rebuild."
      REBUILD_LAYER_ZIP=false
    fi
  fi

  # Check if app needs to be rebuilt
  local REBUILD_APP=true
  if [[ -f "$APP_HASH_FILE" ]] && [[ -f "$APP_OUTPUT_ZIP" ]]; then
    local OLD_HASH=$(cat "$APP_HASH_FILE")
    if [[ "$OLD_HASH" == "$SOURCES_HASH" ]]; then
      _print_info "    No changes detected in sources. Skipping app zip rebuild."
      REBUILD_APP=false
    fi
  fi

  # Build layer zip if needed
  if [[ "$REBUILD_LAYER_ZIP" == true ]]; then
    _print_info "    Building layer zip file..."
    local LAYER_TMP_DIR=$(mktemp -d)
    trap 'rm -rf "$LAYER_TMP_DIR"' EXIT

    cp -R "$LAYER_DIR"/* "$LAYER_TMP_DIR"/
    find "$LAYER_TMP_DIR" -name __pycache__ -type d -exec rm -rf {} + 2>/dev/null || true

    cd "$LAYER_TMP_DIR"
    zip -r -9 "$LAYER_OUTPUT_ZIP" . -x "**/__pycache__/*" "**/*.pyc" "**/*.pyo" "**/*.pth" > /dev/null
    cd "$OLDPWD"

    echo "$LAYER_HASH" > "$LAYER_HASH_FILE"
  fi

  # Build app zip if needed
  if [[ "$REBUILD_APP" == true ]]; then
    _print_info "    Building app zip file..."
    local APP_TMP_DIR=$(mktemp -d)
    trap '[[ -n "${APP_TMP_DIR:-}" ]] && [[ -d "${APP_TMP_DIR:-}" ]] && rm -rf "${APP_TMP_DIR}"' EXIT INT TERM

    cp -R "$SOURCES_DIR"/* "$APP_TMP_DIR"/
    find "$APP_TMP_DIR" -name "*.pth" -type f -exec rm -f {} + 2>/dev/null || true
    find "$APP_TMP_DIR" -name __pycache__ -type d -exec rm -rf {} + 2>/dev/null || true

    cd "$APP_TMP_DIR"
    zip -r -9 "$APP_OUTPUT_ZIP" . -x "**/__pycache__/*" "**/*.pyc" "**/*.pyo" > /dev/null
    cd "$OLDPWD"

    echo "$SOURCES_HASH" > "$APP_HASH_FILE"

    # Clear trap since we're done with APP_TMP_DIR
    trap - EXIT INT TERM
  fi

  # Step 5: Generate signatures.json
  _print_info "  Step 5: Generating signatures.json..."

  if [[ -f "$APP_OUTPUT_ZIP" ]] && [[ -f "$LAYER_OUTPUT_ZIP" ]]; then
    local APP_SHA256=$(shasum -a 256 "$APP_OUTPUT_ZIP" | awk '{print $1}')
    local LAYER_SHA256=$(shasum -a 256 "$LAYER_OUTPUT_ZIP" | awk '{print $1}')

    cat > "$SIGNATURES_FILE" << EOF
{
  "app_sha256": "$APP_SHA256",
  "layer_sha256": "$LAYER_SHA256",
  "app_zip_path": "$APP_OUTPUT_ZIP",
  "layer_zip_path": "$LAYER_OUTPUT_ZIP"
}
EOF
    _print_success "  Runtime module $module built successfully"
    cd "$PROJECT_ROOT"
    return 0
  else
    _print_error "  Failed to create zip files for $module"
    cd "$PROJECT_ROOT"
    return 1
  fi
}

# Build all packages or a specific package
cmd_build() {
  # First build runtime modules from src/runtime/
  local runtime_modules
  mapfile -t runtime_modules < <(_detect_runtime_modules)

  if [[ ${#runtime_modules[@]} -gt 0 ]]; then
    _print_info "Building runtime modules..."
    for module in "${runtime_modules[@]}"; do
      if [[ -n "$module" ]] && [[ "$module" != "" ]]; then
        if [[ -z "$ONLY_PACKAGE" ]] || [[ "$ONLY_PACKAGE" == "$module" ]]; then
          _build_runtime_module "$module" "$SRC_RUNTIME_DIR" || {
            _print_error "Failed to build runtime module: $module"
            exit 1
          }
        fi
      fi
    done
  fi

  # Then build lambda packages from src/lambda/ (as runtime modules)
  local packages
  mapfile -t packages < <(_detect_packages)

  # Filter out empty entries
  local filtered_packages=()
  for pkg in "${packages[@]}"; do
    if [[ -n "$pkg" ]] && [[ "$pkg" != "" ]]; then
      filtered_packages+=("$pkg")
    fi
  done
  packages=("${filtered_packages[@]}")

  if [[ ${#packages[@]} -eq 0 ]] && [[ ${#runtime_modules[@]} -eq 0 ]]; then
    _print_warning "No packages found in $SRC_LAMBDA_DIR or runtime modules in $SRC_RUNTIME_DIR"
    return 0
  fi

  if [[ -n "$ONLY_PACKAGE" ]]; then
    # Check if it's a runtime module first
    local is_runtime=false
    for mod in "${runtime_modules[@]}"; do
      if [[ "$mod" == "$ONLY_PACKAGE" ]]; then
        is_runtime=true
        break
      fi
    done

    if [[ "$is_runtime" == true ]]; then
      # Already built above
      return 0
    elif [[ -d "$SRC_LAMBDA_DIR/$ONLY_PACKAGE" ]] && [[ -f "$SRC_LAMBDA_DIR/$ONLY_PACKAGE/pyproject.toml" ]]; then
      # Build lambda package as runtime module
      _build_runtime_module "$ONLY_PACKAGE" "$SRC_LAMBDA_DIR" || {
        _print_error "Failed to build lambda package as runtime module: $ONLY_PACKAGE"
        exit 1
      }
    else
      _print_error "Package not found or missing pyproject.toml: $ONLY_PACKAGE"
      if [[ ${#packages[@]} -gt 0 ]]; then
        _print_info "Available lambda packages: ${packages[*]}"
      fi
      if [[ ${#runtime_modules[@]} -gt 0 ]]; then
        _print_info "Available runtime modules: ${runtime_modules[*]}"
      fi
      exit 1
    fi
  else
    if [[ ${#packages[@]} -gt 0 ]]; then
      _print_info "Building all lambda packages as runtime modules..."
      for package in "${packages[@]}"; do
        if [[ -n "$package" ]] && [[ "$package" != "" ]]; then
          _build_runtime_module "$package" "$SRC_LAMBDA_DIR" || {
            _print_error "Failed to build lambda package: $package"
            exit 1
          }
        fi
      done
    fi
  fi

  _print_success "Build complete"
}

# Test a runtime module (validates signatures.json, layer zip, app zip)
_test_runtime_module() {
  local module="$1"
  local OUTPUT_DIR="$OUT_DIR/$module"
  local SIGNATURES_FILE="$OUTPUT_DIR/signatures.json"
  local APP_OUTPUT_ZIP="$OUTPUT_DIR/lambda_app.zip"
  local LAYER_OUTPUT_ZIP="$OUTPUT_DIR/lambda_layer.zip"

  if [[ ! -f "$SIGNATURES_FILE" ]]; then
    _print_warning "Runtime module not built: $module. Building now..."
    # Determine if it's from runtime or lambda directory
    if [[ -d "$SRC_RUNTIME_DIR/$module" ]]; then
      _build_runtime_module "$module" "$SRC_RUNTIME_DIR" || return 1
    elif [[ -d "$SRC_LAMBDA_DIR/$module" ]]; then
      _build_runtime_module "$module" "$SRC_LAMBDA_DIR" || return 1
    else
      _print_error "Module not found: $module"
      return 1
    fi
  fi

  _print_info "Testing runtime module: $module"

  # Validate signatures.json exists and is valid JSON
  if [[ ! -f "$SIGNATURES_FILE" ]]; then
    _print_error "signatures.json not found: $SIGNATURES_FILE"
    return 1
  fi

  # Check if signatures.json is valid JSON
  if ! python3 -m json.tool "$SIGNATURES_FILE" > /dev/null 2>&1; then
    _print_error "Invalid JSON in signatures.json: $SIGNATURES_FILE"
    return 1
  fi

  # Extract paths from signatures.json
  local app_zip_path=$(python3 -c "import json; print(json.load(open('$SIGNATURES_FILE'))['app_zip_path'])" 2>/dev/null)
  local layer_zip_path=$(python3 -c "import json; print(json.load(open('$SIGNATURES_FILE'))['layer_zip_path'])" 2>/dev/null)

  if [[ -z "$app_zip_path" ]] || [[ -z "$layer_zip_path" ]]; then
    _print_error "Missing paths in signatures.json"
    return 1
  fi

  # Validate app zip exists and is valid
  if [[ ! -f "$app_zip_path" ]]; then
    _print_error "App zip not found: $app_zip_path"
    return 1
  fi

  if ! unzip -t "$app_zip_path" > /dev/null 2>&1; then
    _print_error "Invalid app zip file: $app_zip_path"
    return 1
  fi

  # Validate layer zip exists and is valid
  if [[ ! -f "$layer_zip_path" ]]; then
    _print_error "Layer zip not found: $layer_zip_path"
    return 1
  fi

  if ! unzip -t "$layer_zip_path" > /dev/null 2>&1; then
    _print_error "Invalid layer zip file: $layer_zip_path"
    return 1
  fi

  # Check file sizes
  local app_size=$(stat -f%z "$app_zip_path" 2>/dev/null || stat -c%s "$app_zip_path" 2>/dev/null || echo "0")
  local layer_size=$(stat -f%z "$layer_zip_path" 2>/dev/null || stat -c%s "$layer_zip_path" 2>/dev/null || echo "0")
  local app_size_mb=$((app_size / 1024 / 1024))
  local layer_size_mb=$((layer_size / 1024 / 1024))

  if [[ $app_size_mb -gt 50 ]]; then
    _print_warning "App zip size is ${app_size_mb}MB (Lambda limit: 50MB uncompressed)"
  fi

  if [[ $layer_size_mb -gt 250 ]]; then
    _print_warning "Layer zip size is ${layer_size_mb}MB (Lambda limit: 250MB uncompressed)"
  fi

  _print_success "Runtime module $module passed validation"
  return 0
}

# Test a single package (deprecated - kept for backward compatibility)
# Now redirects to runtime module testing
_test_package() {
  local package="$1"
  # All packages with pyproject.toml are now runtime modules
  _test_runtime_module "$package"
}

# Test all packages or a specific package
cmd_test() {
  # Run build first
  _print_info "Running build first..."
  cmd_build

  local failed=0

  # Test runtime modules from src/runtime/
  local runtime_modules
  mapfile -t runtime_modules < <(_detect_runtime_modules)

  if [[ ${#runtime_modules[@]} -gt 0 ]]; then
    _print_info "Testing runtime modules..."
    for module in "${runtime_modules[@]}"; do
      if [[ -n "$module" ]] && [[ "$module" != "" ]]; then
        if [[ -z "$ONLY_PACKAGE" ]] || [[ "$ONLY_PACKAGE" == "$module" ]]; then
          _test_runtime_module "$module" || failed=1
        fi
      fi
    done
  fi

  # Test lambda packages from src/lambda/ (as runtime modules)
  local packages
  mapfile -t packages < <(_detect_packages)

  # Filter out empty entries
  local filtered_packages=()
  for pkg in "${packages[@]}"; do
    if [[ -n "$pkg" ]] && [[ "$pkg" != "" ]]; then
      filtered_packages+=("$pkg")
    fi
  done
  packages=("${filtered_packages[@]}")

  if [[ ${#packages[@]} -gt 0 ]]; then
    _print_info "Testing lambda packages..."
    if [[ -n "$ONLY_PACKAGE" ]]; then
      # Check if it's a runtime module first
      local is_runtime=false
      for mod in "${runtime_modules[@]}"; do
        if [[ "$mod" == "$ONLY_PACKAGE" ]]; then
          is_runtime=true
          break
        fi
      done

      if [[ "$is_runtime" == false ]] && [[ -d "$SRC_LAMBDA_DIR/$ONLY_PACKAGE" ]] && [[ -f "$SRC_LAMBDA_DIR/$ONLY_PACKAGE/pyproject.toml" ]]; then
        _test_runtime_module "$ONLY_PACKAGE" || failed=1
      fi
    else
      for package in "${packages[@]}"; do
        if [[ -n "$package" ]] && [[ "$package" != "" ]]; then
          _test_runtime_module "$package" || failed=1
        fi
      done
    fi
  fi

  if [[ ${#runtime_modules[@]} -eq 0 ]] && [[ ${#packages[@]} -eq 0 ]]; then
    _print_warning "No runtime modules or packages found to test"
    return 0
  fi

  if [[ $failed -eq 0 ]]; then
    _print_success "All tests passed"
  else
    _print_error "Some tests failed"
    exit 1
  fi
}

# Get layer directory path
_get_layer_path() {
  local layer="$1"
  local env="$2"

  if [[ -v LAYER_MAP["$layer"] ]]; then
    local layer_dir="${LAYER_MAP[$layer]}"
    echo "$DEPLOY_DIR/$layer_dir/environments/$env"
  else
    _print_error "Unknown layer: $layer"
    return 1
  fi
}

# Deploy a single layer
_deploy_layer() {
  local layer="$1"
  local env="$2"
  local layer_path

  layer_path=$(_get_layer_path "$layer" "$env")

  if [[ ! -d "$layer_path" ]]; then
    _print_error "Layer environment not found: $layer_path"
    return 1
  fi

  _print_info "Deploying layer: $layer (environment: $env)"

  cd "$layer_path"

  # Check if terraform.tfvars exists
  if [[ ! -f "terraform.tfvars" ]]; then
    _print_warning "terraform.tfvars not found, checking for example file..."
    if [[ -f "terraform.tfvars.example" ]]; then
      _print_error "Please copy terraform.tfvars.example to terraform.tfvars and configure it"
      return 1
    else
      _print_error "No terraform.tfvars or terraform.tfvars.example found"
      return 1
    fi
  fi

  # Initialize Terraform if .terraform directory doesn't exist
  if [[ ! -d ".terraform" ]]; then
    _print_info "Initializing Terraform..."
    terraform init
  fi

  # Plan
  _print_info "Running terraform plan..."
  if ! terraform plan -var-file=terraform.tfvars -out=tfplan; then
    _print_error "Terraform plan failed"
    return 1
  fi

  # Apply
  _print_info "Applying Terraform changes..."
  if terraform apply tfplan; then
    _print_success "Layer $layer deployed successfully"
    rm -f tfplan
    return 0
  else
    _print_error "Terraform apply failed"
    rm -f tfplan
    return 1
  fi
}

# Deploy infrastructure
cmd_deploy() {
  check_prerequisites

  # Run build first
  _print_info "Running build first..."
  cmd_build

  local layers=()
  local failed=0

  if [[ -n "$ONLY_LAYER" ]]; then
    # Check if it's a valid layer
    if [[ ! -v LAYER_MAP["$ONLY_LAYER"] ]]; then
      _print_error "Unknown layer: $ONLY_LAYER"
      _print_info "Available layers: ${!LAYER_MAP[*]}"
      exit 1
    fi
    layers=("$ONLY_LAYER")
  else
    # Deploy all layers in order: core -> infra -> app
    layers=("core" "infra" "app")
  fi

  _print_info "Deploying to environment: $ENV"

  for layer in "${layers[@]}"; do
    if ! _deploy_layer "$layer" "$ENV"; then
      failed=1
      # If core fails, don't continue with other layers
      if [[ "$layer" == "core" ]]; then
        _print_error "Core layer deployment failed. Cannot proceed with other layers."
        exit 1
      fi
      _print_warning "Layer $layer deployment failed, continuing with next layer..."
    fi
  done

  if [[ $failed -eq 0 ]]; then
    _print_success "Deployment complete"
  else
    _print_error "Deployment completed with errors"
    exit 1
  fi
}

# Run command in package environment
cmd_run() {
  local args=("$@")

  if [[ ${#args[@]} -lt 2 ]]; then
    _print_error "Error: cb run requires <package> <command>"
    _print_info "Example: cb run lambda-api python -m pytest"
    exit 1
  fi

  local package="${args[0]}"
  local command_args=("${args[@]:1}")
  local package_dir="$SRC_LAMBDA_DIR/$package"

  if [[ ! -d "$package_dir" ]]; then
    _print_error "Package not found: $package"
    local packages
    mapfile -t packages < <(_detect_packages)
    if [[ ${#packages[@]} -gt 0 ]]; then
      _print_info "Available packages: ${packages[*]}"
    fi
    exit 1
  fi

  _print_info "Running command in package: $package"
  _print_info "Command: ${command_args[*]}"

  cd "$package_dir"
  # If it's a Python package, set up UV environment
  if _is_python_package "$package_dir"; then
    check_uv
    _print_info "Setting up Python environment with UV..."

    # Check if cybernetika-runner exists
    if command -v cybernetika-runner &> /dev/null; then
      cybernetika-runner "${command_args[@]}"
    else
      # Use UV to run the command with proper environment
      if [[ -f "requirements.txt" ]] || [[ -f "pyproject.toml" ]]; then
        # Use UV to run command with dependencies installed
        uv run "${command_args[@]}"
      else
        # Execute command directly
        "${command_args[@]}"
      fi
    fi
  else
    # Check if cybernetika-runner exists
    if command -v cybernetika-runner &> /dev/null; then
      cybernetika-runner "${command_args[@]}"
    else
      # Execute command directly
      "${command_args[@]}"
    fi
  fi
}

# Main execution
main() {
  # Handle empty arguments - show help
  if [[ $# -eq 0 ]]; then
    _show_help
    exit 0
  fi

  # Handle --help flag before parsing
  for arg in "$@"; do
    if [[ "$arg" == "--help" ]] || [[ "$arg" == "-h" ]]; then
      _show_help
      exit 0
    fi
  done

  local parsed
  parsed=$(parse_args "$@")

  # parse_args already handles showing help and exiting, so if we get here with empty output,
  # something went wrong
  if [[ -z "$parsed" ]]; then
    exit 0
  fi

  local cmd_line
  read -r cmd_line <<< "$parsed"
  local cmd="$cmd_line"

  local args_str
  args_str=$(echo "$parsed" | tail -n +2)
  local args=()
  while IFS= read -r line; do
    [[ -n "$line" ]] && args+=("$line")
  done <<< "$args_str"

  case "$cmd" in
    build)
      cmd_build
      ;;
    test)
      cmd_test
      ;;
    deploy)
      cmd_deploy
      ;;
    run)
      cmd_run "${args[@]}"
      ;;
    *)
      _print_error "Unknown command: $cmd"
      _show_help
      exit 1
      ;;
  esac
}

# Run main function
main "$@"
